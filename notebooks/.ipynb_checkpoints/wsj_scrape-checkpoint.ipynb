{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import html5lib\n",
    "import pandas as pd\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.keys import Keys   \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from datetime import date, timedelta, datetime as dt\n",
    "from pymongo import MongoClient\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client =  MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client['WallStreet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RemoteDriverStartService():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Set user app data to a new directory\n",
    "    options.add_argument(\"user-data-dir=C:\\\\Users\\\\Donley\\\\App Data\\\\Google\\\\Chrome\\\\Application\\\\User Data\\\\Kit\")\n",
    "    options.add_experimental_option(\"Proxy\", \"null\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"ignore-certificate-errors\"])\n",
    "    # Create a download path for external data sources as default: \n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "      \"download.default_directory\": r\"C:\\Users\\Donley\\Documents\\GA_TECH\\SUBMISSIONS\\PROJECT2-CHALLENGE\\data\\external\",\n",
    "      \"download.prompt_for_download\": False,\n",
    "      \"download.directory_upgrade\": True,\n",
    "      \"safebrowsing.enabled\": True\n",
    "    }),\n",
    "    # Add those optional features to capabilities\n",
    "    caps = options.to_capabilities()  \n",
    "    def start_driver(self):\n",
    "        return webdriver.Remote(command_executor='http://127.0.0.1:4444', \n",
    "                                desired_capabilities=self.caps)\n",
    "# Set class equal to new capabilities:\n",
    "DesiredCapabilities = RemoteDriverStartService()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables for scraping: \n",
    "wsj = \"https://www.wsj.com/market-data/stocks?mod=nav_top_subsection\"\n",
    "# Download data to paths, csv's, json, etc: \n",
    "    # for external data sources\n",
    "external = \"../data/external/\"\n",
    "    # for processed data sources with ID's\n",
    "processed = \"../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate Driver in system\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# save the .exe file under the same directory of the web-scrape python script.\n",
    "Path = os.path.join(current_path, \"chromedriver\")\n",
    "\n",
    "# Initialize Chrome driver and start browser session controlled by automated test software under Kit profile.\n",
    "caps = webdriver.DesiredCapabilities.CHROME.copy()\n",
    "caps['acceptInsecureCerts'] = True\n",
    "# caps = webdriver.DesiredCapabilities.CHROME.copy()\n",
    "# caps['acceptInsecureCerts'] = True\n",
    "# driver = webdriver.Chrome(options=options, desired_capabilities=caps)\n",
    "driver = webdriver.Chrome(executable_path='chromedriver', desired_capabilities=caps)\n",
    "\n",
    "# Get the URL\n",
    "driver.get(wsj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Find the IDs of the items we want to scrape for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give it time to search for ID and allow the page time to load:\n",
    "timeout = 30\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.ID, \"root\")))\n",
    "except TimeoutException:\n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Techniques to make more human-like web-scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the website detects us as a web-scraper, it will cut our connection so we cannot pull more data and have to re-start our scraper. This largely impacts the efficiency of the scraper and involves a lot of manual interference. There are a few techniques we can use to make the scraper more human-like:\n",
    "# (1) Randomize the sleep time\n",
    "# This can be easily implemented as below wherever needed:\n",
    "#sleep for sometime between 5 and 8 seconds\n",
    "# time.sleep(random.uniform(5,8))\n",
    "# (2) Randomize the user agent for the web browser\n",
    "# This is also easy and can be added to the browser options as below:\n",
    "# ua = UserAgent()\n",
    "# userAgent = ua.random\n",
    "# Firefox_options = webdriver.FirefoxOptions()\n",
    "# Firefox_options.add_argument(f’user-agent={userAgent}’)\n",
    "# browser = webdriver.Firefox(executable_path = DRIVER_BIN, options=Firefox_options)\n",
    "# (3) Use dynamic proxy/IP\n",
    "# This requires more work than the above two. Usually free proxies are not stable and most of them don’t respond to requests, so we need to first a free proxy that responds to our requests. This website (also named as “url” in the script below) provides a lot of free proxies which we scrape down for our use. We will use Python BeautifulSoup package to scrape a list of proxies, and use Python requests package to test whether the proxy responds to our requests to the link.\n",
    "# def get_proxy(link):\n",
    "#     url = \"https://www.sslproxies.org/\"\n",
    "#     r = requests.get(url)\n",
    "#     soup = BeautifulSoup(r.content, 'html5lib')\n",
    "#     proxies_list = list(map(lambda x: x[0]+':'+x[1], list(zip(map(lambda x: x.text, soup.findAll('td')[::8]), map(lambda x: x.text, soup.findAll('td')[1::8])))))\n",
    "#     while 1:\n",
    "#         try:\n",
    "#             selected_ip = choice(proxies_list)\n",
    "#             proxy = {'https': selected_ip, 'http': selected_ip}\n",
    "#             headers = {'User-Agent': ua.random}\n",
    "#             print('Using proxy:{}'.format(proxy))\n",
    "#             r = requests.request('get', link, proxies=proxy, headers=headers, timeout=5)\n",
    "#             break\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "#     return proxy\n",
    "# We then add the working proxy to the browser option, similar to how we added the fake user agent:\n",
    "# link = \"https://www.expedia.com\"\n",
    "# proxy = get_proxy(link)\n",
    "# Firefox_options.add_argument('--proxy-server=%s' % proxy)\n",
    "# browser = webdriver.Firefox(executable_path = DRIVER_BIN, options=Firefox_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: The full code that runs the scraper and save the data to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[              Unnamed: 0      Last     Chg  %Chg\n",
       " 0                   DJIA  28679.81 -157.71 -0.55\n",
       " 1       Nasdaq Composite  11863.90  -12.36 -0.10\n",
       " 2                S&P 500   3511.93  -22.29 -0.63\n",
       " 3  DJ Total Stock Market  36031.93 -192.19 -0.53\n",
       " 4           Russell 2000   1636.85  -12.21 -0.74\n",
       " 5         NYSE Composite  13211.95 -112.93 -0.85\n",
       " 6           Barron's 400    762.93   -4.08 -0.53\n",
       " 7        CBOE Volatility     26.07    1.00  3.99\n",
       " 8           DJIA Futures  28568.00 -230.00 -0.80\n",
       " 9        S&P 500 Futures   3501.75  -31.05 -0.88,\n",
       "   Unnamed: 0_level_0               NYSE             Nasdaq\n",
       "               Issues Unnamed: 1_level_1 Unnamed: 2_level_1\n",
       "            Issues At Unnamed: 1_level_2 Unnamed: 2_level_2\n",
       "         Share Volume Unnamed: 1_level_3 Unnamed: 2_level_3\n",
       " 0          Advancing                998               1381\n",
       " 1          Declining               2048               2065\n",
       " 2          Unchanged                 91                 97\n",
       " 3              Total               3137               3543\n",
       " 4          New Highs                100                152\n",
       " 5           New Lows                 17                 20\n",
       " 6              Total         3826281378         3724593716\n",
       " 7          Advancing          952627429         1689113493\n",
       " 8          Declining         2850709410         2001245143\n",
       " 9          Unchanged           22944539           34235080,\n",
       "                            Unnamed: 0  Volume   Last   Chg  % Chg\n",
       " 0                  SOS Ltd. ADR (SOS)   10.5M   2.69  0.58  27.49\n",
       " 1    Enlivex Therapeutics Ltd. (ENLV)    1.8M  13.87  2.57  22.74\n",
       " 2    Larimar Therapeutics Inc. (LRMR)  231.0K  18.91  3.48  22.55\n",
       " 3                iHuman Inc. ADR (IH)    3.0M  27.15  4.71  20.99\n",
       " 4  MoneyGram International Inc. (MGI)    7.6M   3.85  0.65  20.31,\n",
       "                          New Highs  Unnamed: 1\n",
       " 0   Alibaba Group Holding Ltd. ADR      309.64\n",
       " 1          UnitedHealth Group Inc.      333.56\n",
       " 2  United Parcel Service Inc. Cl B      176.80\n",
       " 3                      Lowe's Cos.      175.00\n",
       " 4                  ServiceNow Inc.      515.55,\n",
       "                   New Lows  Unnamed: 1\n",
       " 0          Asana Inc. Cl A       24.38\n",
       " 1           CoreCivic Inc.        7.76\n",
       " 2     Peabody Energy Corp.        1.90\n",
       " 3     VIA optronics AG ADR        8.09\n",
       " 4  Genesis Healthcare Inc.        0.50,\n",
       "                 Unnamed: 0  % Chg\n",
       " 0                  S&P 500  -0.63\n",
       " 1   Communication Services   0.34\n",
       " 2   Consumer Discretionary   0.03\n",
       " 3         Consumer Staples  -0.01\n",
       " 4                   Energy  -1.56\n",
       " 5               Financials  -1.86\n",
       " 6              Health Care  -0.72\n",
       " 7              Industrials  -1.06\n",
       " 8   Information Technology  -0.63\n",
       " 9                Materials  -0.94\n",
       " 10             Real Estate  -1.70\n",
       " 11               Utilities  -0.71]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Html to generate S&P 500 table: \n",
    "table = driver.find_element_by_id(\"root\").get_attribute('outerHTML')\n",
    "tables  = pd.read_html(table)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate List of tables on page:\n",
    "wsj_tables =[df for df in tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P 500 &amp; Sectors</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S&amp;P 500</td>\n",
       "      <td>-0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Communication Services</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Energy</td>\n",
       "      <td>-1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Financials</td>\n",
       "      <td>-1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Health Care</td>\n",
       "      <td>-0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Industrials</td>\n",
       "      <td>-1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>-0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Materials</td>\n",
       "      <td>-0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Real Estate</td>\n",
       "      <td>-1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Utilities</td>\n",
       "      <td>-0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         S&P 500 & Sectors  % Change\n",
       "0                  S&P 500     -0.63\n",
       "1   Communication Services      0.34\n",
       "2   Consumer Discretionary      0.03\n",
       "3         Consumer Staples     -0.01\n",
       "4                   Energy     -1.56\n",
       "5               Financials     -1.86\n",
       "6              Health Care     -0.72\n",
       "7              Industrials     -1.06\n",
       "8   Information Technology     -0.63\n",
       "9                Materials     -0.94\n",
       "10             Real Estate     -1.70\n",
       "11               Utilities     -0.71"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get table 5 and rename columns:\n",
    "sp500_sectors_df = wsj_tables[5]\n",
    "sp500_sectors_df.columns = [\"S&P 500 & Sectors\", \"% Change\"]\n",
    "sp500_sectors_df.reset_index(drop=True, inplace=True)\n",
    "sp500_sectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_sectors_df.to_csv(external+\"sp500.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>S&amp;P 500 &amp; Sectors</th>\\n      <th>% Change</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>S&amp;P 500</td>\\n      <td>-0.63</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Communication Services</td>\\n      <td>0.34</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Consumer Discretionary</td>\\n      <td>0.03</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Consumer Staples</td>\\n      <td>-0.01</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Energy</td>\\n      <td>-1.56</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Financials</td>\\n      <td>-1.86</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Health Care</td>\\n      <td>-0.72</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>Industrials</td>\\n      <td>-1.06</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>Information Technology</td>\\n      <td>-0.63</td>\\n    </tr>\\n    <tr>\\n      <th>9</th>\\n      <td>Materials</td>\\n      <td>-0.94</td>\\n    </tr>\\n    <tr>\\n      <th>10</th>\\n      <td>Real Estate</td>\\n      <td>-1.70</td>\\n    </tr>\\n    <tr>\\n      <th>11</th>\\n      <td>Utilities</td>\\n      <td>-0.71</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_sectors_html = sp500_sectors_df.to_html()\n",
    "sp500_sectors_table = str(sp500_sectors_html)\n",
    "sp500_sectors_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x2891bd0ca00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj_collection = db['SP500_Change']\n",
    "# Insert collection\n",
    "wsj_collection.update_many({},{\"$set\": {\"S&P 500\":sp500_sectors_table}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index of the links needed\n",
    "# 0\tS&P 500\n",
    "# 1\tCommunication Services\n",
    "# 2\tConsumer Discretionary\n",
    "# 3\tConsumer Staples\n",
    "# 4\tEnergy\n",
    "# 5\tFinancials\n",
    "# 6\tHealth Care\n",
    "# 7\tIndustrials\n",
    "# 8\tInformation Technology\n",
    "# 9\tMaterials\n",
    "# 10\tReal Estate\n",
    "# 11\tUtilities\n",
    "sp500_links = [(driver.find_elements_by_partial_link_text(sector)) for sector in sp500_sectors_df[\"S&P 500 & Sectors\"]]\n",
    "\n",
    "# variable Links to individual sector pages: \n",
    "sp500_link = [links.get_attribute(\"href\") for links in sp500_links[0]]\n",
    "communication_link = [links.get_attribute(\"href\") for links in sp500_links[1]]\n",
    "discretionary_link = [links.get_attribute(\"href\") for links in sp500_links[2]]\n",
    "staples_link = [links.get_attribute(\"href\") for links in sp500_links[3]]\n",
    "energy_link = [links.get_attribute(\"href\") for links in sp500_links[4]]\n",
    "financials_link = [links.get_attribute(\"href\") for links in sp500_links[5]]\n",
    "health_link = [links.get_attribute(\"href\") for links in sp500_links[6]]\n",
    "industrials_link = [links.get_attribute(\"href\") for links in sp500_links[7]]\n",
    "information_Technology_link = [links.get_attribute(\"href\") for links in sp500_links[8]]\n",
    "materials_link = [links.get_attribute(\"href\") for links in sp500_links[9]]\n",
    "real_estate_link = [links.get_attribute(\"href\") for links in sp500_links[10]]\n",
    "utilities_link = [links.get_attribute(\"href\") for links in sp500_links[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of links for sectors: \n",
    "sector_links = [sp500_link, communication_link, discretionary_link, staples_link, energy_link, financials_link, health_link, industrials_link, information_Technology_link, materials_link, real_estate_link, utilities_link]\n",
    "sector_dict = {\"Top Sector Links\": sector_links}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x2891bf3c700>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsjlink_collection = db['SP500_Links']\n",
    "wsjlink_collection.update_many({},{\"$set\": sector_dict} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get to Historical Data:\n",
    "driver.get(sp500_link[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"08bb593b3ed160df94e608265fbbafb7\", element=\"805839cd-6916-4c2e-8434-46a1e0a5d459\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"08bb593b3ed160df94e608265fbbafb7\", element=\"8bd8261b-ca3e-47a8-ba60-77554a2553de\")>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data = driver.find_elements(By.CSS_SELECTOR, 'a.moreLink')\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get to historical data download page: \n",
    "historical_data[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10/13/2020'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todays date\n",
    "currentDate = date.today()\n",
    "today = currentDate.strftime('%m/%d/%Y')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10/14/2019'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date 1 week ago from today\n",
    "five_days = currentDate - timedelta(days=365)\n",
    "five = five_days.strftime('%m/%d/%Y')\n",
    "five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out Date From Form\n",
    "text_area = driver.find_element(By.CSS_SELECTOR, \"#selectDateFrom\")\n",
    "text_area.send_keys(Keys.CONTROL, \"a\")  # or Keys.COMMAND on Mac\n",
    "text_area.send_keys(five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out Date to\n",
    "text_area2 = driver.find_element(By.CSS_SELECTOR, \"#selectDateTo\")\n",
    "text_area2.send_keys(Keys.CONTROL, \"a\")  # or Keys.COMMAND on Mac\n",
    "text_area2.send_keys(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data\n",
    "generate_data = driver.find_element(By.ID, \"datPickerButton\")\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.ID, \"datPickerButton\")))\n",
    "except TimeoutException:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download as csv  \n",
    "download_sheet = driver.find_element(By.ID, \"dl_spreadsheet\")\n",
    "try:\n",
    "    WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.ID, \"dl_spreadsheet\")))\n",
    "except TimeoutException:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_sheet.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = pd.read_csv('../data/external/HistoricalPrices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Date     Open     High      Low    Close\\n0    10/06/20  3408.74  3431.56  3354.54  3360.95\\n1    10/05/20  3367.27  3409.57  3367.27  3408.63\\n2    10/02/20  3338.94  3369.10  3323.69  3348.44\\n3    10/01/20  3385.87  3397.18  3361.39  3380.80\\n4    09/30/20  3341.21  3393.56  3340.47  3363.00\\n..        ...      ...      ...      ...      ...\\n247  10/14/19  2965.81  2972.84  2962.94  2966.15\\n248  10/11/19  2963.07  2993.28  2963.07  2970.27\\n249  10/10/19  2918.55  2948.46  2917.12  2938.13\\n250  10/09/19  2911.10  2929.32  2907.41  2919.40\\n251  10/08/19  2920.40  2925.47  2892.66  2893.06\\n\\n[252 rows x 5 columns]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df.to_html()\n",
    "sp_df_table = str(sp_df)\n",
    "sp_df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.UpdateResult at 0x2891bf678c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj_collection = db['S&P 500: Historical Prices']\n",
    "wsj_collection.update_many({},{\"$set\": {\"Historical Prices\":sp_df_table}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileReport(sp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd72a5aa1b544c51a115c76b83b3bcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Export report to file', max=1.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prof.to_file(output_file='../app/templates/profile.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
